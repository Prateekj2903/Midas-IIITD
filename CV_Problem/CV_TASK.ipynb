{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = namedtuple('Config', ['batch_size', 'image_shape', 'num_classes', 'epochs'])\n",
    "active_config = Config(32, (28,28,1), 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    DATA_DIR_NAME = 'data'\n",
    "    TRAINING_IMG_FILENAME = 'train_image.pkl' \n",
    "    TRAINING_LABEL_FILENAME = 'train_label.pkl'\n",
    "    TESTING_IMG_FILENAME = 'test_image.pkl'\n",
    "    \n",
    "    def __init__(self, validation_size=0.2):\n",
    "        self.validation_size = validation_size\n",
    "        self.build()\n",
    "    \n",
    "    @property\n",
    "    def training_set_size(self):\n",
    "        return len(self.training_images)\n",
    "    \n",
    "    @property\n",
    "    def validation_set_size(self):\n",
    "        return len(self.validation_images)\n",
    "    \n",
    "    @property\n",
    "    def test_set_size(self):\n",
    "        return len(self.test_set)\n",
    "    \n",
    "    \n",
    "    def build(self):\n",
    "        self.images = self.load_pickle(os.path.join(self.DATA_DIR_NAME, self.TRAINING_IMG_FILENAME))\n",
    "        self.labels = self.load_pickle(os.path.join(self.DATA_DIR_NAME, self.TRAINING_LABEL_FILENAME))\n",
    "        self.training_images, self.validation_images, self.training_labels, self.validation_labels = train_test_split(self.images, self.labels, test_size=self.validation_size)\n",
    "        \n",
    "        self.training_set = self.build_set(self.training_images, self.training_labels)\n",
    "        self.validation_set = self.build_set(self.validation_images, self.validation_labels)\n",
    "        self.test_set = self.load_pickle(os.path.join(self.DATA_DIR_NAME, self.TESTING_IMG_FILENAME))\n",
    "        \n",
    "    def build_set(self, images, labels):\n",
    "        return [images, labels]\n",
    "        \n",
    "    def load_pickle(self, filename, mode='rb'):\n",
    "        data = pickle.load(open(filename, mode))\n",
    "        data = np.array(data, dtype='float32')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 784) (1600, 784)\n",
      "(6400,) (1600,)\n",
      "6400 1600 2000\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "dataset = Dataset()\n",
    "print(dataset.training_set[0].shape, dataset.validation_set[0].shape)\n",
    "print(dataset.training_set[1].shape, dataset.validation_set[1].shape)\n",
    "print(dataset.training_set_size, dataset.validation_set_size, dataset.test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetProvider():\n",
    "    def __init__(self, augment=False, validation_size=0.2, batch_size=None, num_classes=None):\n",
    "        self.dataset = Dataset(validation_size)\n",
    "        self.augment = augment\n",
    "        self.batch_size = batch_size or active_config.batch_size\n",
    "        self.num_classes = num_classes or active_config.num_classes\n",
    "    \n",
    "    @property\n",
    "    def training_steps(self):\n",
    "        return int(dataset.training_set_size/ self.batch_size)\n",
    "    \n",
    "    @property\n",
    "    def validation_steps(self):\n",
    "        return int(dataset.test_set_size/ self.batch_size)\n",
    "    \n",
    "    def training_set(self):\n",
    "        for batch in self.generate_batch(self.dataset.training_set):\n",
    "            yield batch\n",
    "    \n",
    "    def validation_set(self):\n",
    "        for batch in self.generate_batch(self.dataset.validation_set):\n",
    "            yield batch\n",
    "    \n",
    "    def generate_batch(self, img_label_set):\n",
    "        while True:\n",
    "            all_idx = np.arange(len(img_label_set[0]))\n",
    "            random_idx = np.random.choice(all_idx, size=self.batch_size)\n",
    "            random_img = img_label_set[0][random_idx]\n",
    "            random_label = img_label_set[1][random_idx]\n",
    "            yield self.preprocess_batch([random_img, random_label])\n",
    "            \n",
    "    def preprocess_batch(self, img_label_batch):\n",
    "        return self.preprocess_images(img_label_batch[0]), self.preprocess_labels(img_label_batch[1])\n",
    "    \n",
    "    def preprocess_images(self, imgs):\n",
    "        #TODO add augment code\n",
    "        if self.augment:\n",
    "            imgs = imgs/255.\n",
    "        return np.reshape(imgs, (imgs.shape[0], 28, 28, 1))\n",
    "    \n",
    "    def preprocess_labels(self, labels):\n",
    "        labels[labels == 2] = 1\n",
    "        labels[labels == 3] = 2\n",
    "        labels[labels == 6] = 3\n",
    "        return to_categorical(labels, num_classes=self.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 28, 28, 1), (32, 4))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_provider = DatasetProvider()\n",
    "batch = next(dataset_provider.training_set())\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifierModel():\n",
    "    \n",
    "    def __init__(self, learning_rate=0.001, print_summary=False, image_shape=None, num_classes=None):\n",
    "        #TODO\n",
    "        #initialize params and hyperparams\n",
    "        self.image_shape = image_shape or active_config.image_shape\n",
    "        self.num_classes = num_classes or active_config.num_classes\n",
    "        self.optimizer = Adam(lr=learning_rate)\n",
    "        self.print_summary = print_summary\n",
    "        self.model = self.build()\n",
    "    \n",
    "    def build(self):\n",
    "        #TODO\n",
    "        #define model and build model\n",
    "        input_layer = Input(shape=self.image_shape)\n",
    "        x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_layer)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(units=1024, activation='relu')(x)\n",
    "        x = Dense(units=512, activation='relu')(x)\n",
    "        output_layer = Dense(units=self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        if self.print_summary:\n",
    "            print(model.summary())\n",
    "        \n",
    "        model.compile(optimizer=self.optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training():\n",
    "    def __init__(self, augment=False, learning_rate=0.001, print_summary=False, epochs=None):\n",
    "        \n",
    "        self.dataset_provider = DatasetProvider(augment)\n",
    "        self.model = ImageClassifierModel(learning_rate, print_summary).model\n",
    "        self.epochs = epochs or active_config.epochs\n",
    "        \n",
    "    def callbacks(self):\n",
    "        #TODO Define Callbacks\n",
    "        callbacks = []\n",
    "        return callbacks\n",
    "    \n",
    "    def run(self):\n",
    "        self.history = self.model.fit_generator(self.dataset_provider.training_set(), \n",
    "                                                steps_per_epoch=self.dataset_provider.training_steps, \n",
    "                                                epochs=self.epochs, \n",
    "                                                validation_data=self.dataset_provider.validation_set(), \n",
    "                                                validation_steps=self.dataset_provider.validation_steps)\n",
    "    \n",
    "    def visualize(self):\n",
    "        #TODO\n",
    "        # 1. Vizualize augmented images\n",
    "        # 2. vizualize model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1024)              22152192  \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 22,679,364\n",
      "Trainable params: 22,679,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 12.0256 - acc: 0.2539 - val_loss: 11.9748 - val_acc: 0.2571\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 12.1415 - acc: 0.2467 - val_loss: 12.2186 - val_acc: 0.2419\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 12.1566 - acc: 0.2458 - val_loss: 12.1698 - val_acc: 0.2450\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 12.1515 - acc: 0.2461 - val_loss: 12.2511 - val_acc: 0.2399\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 12.0155 - acc: 0.2545 - val_loss: 12.0804 - val_acc: 0.2505\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 12.1339 - acc: 0.2472 - val_loss: 12.1129 - val_acc: 0.2485\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 12.0181 - acc: 0.2544 - val_loss: 11.7880 - val_acc: 0.2686\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 12.1213 - acc: 0.2480 - val_loss: 12.0723 - val_acc: 0.2510\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 12.2296 - acc: 0.2412 - val_loss: 12.0804 - val_acc: 0.2505\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 12.0936 - acc: 0.2497 - val_loss: 12.1779 - val_acc: 0.2445\n"
     ]
    }
   ],
   "source": [
    "train = Training(print_summary=True)\n",
    "train.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
